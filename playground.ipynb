{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8963b6a-8ebe-4924-ab31-d90d683e4acd",
   "metadata": {},
   "source": [
    "simple test if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc75c2-a529-4f63-9dd3-d8ce47f0799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evo import Evo\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bbeef-fa04-4708-becd-7aaa727ee639",
   "metadata": {},
   "source": [
    "### Importing both datasets (RefSeq & DeePhage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a80e225-9ca0-45ff-ad06-d0852a28ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de refseq_simulated_metagenome.zip (ZIP)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://figshare.com/ndownloader/articles/19739884/versions/1\n",
      "To: d:\\K Docs\\Phagos x AWS\\phage-classification-hackathon\\refseq_simulated_metagenome.zip\n",
      "100%|██████████| 975M/975M [00:42<00:00, 23.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction de refseq_simulated_metagenome.zip...\n",
      "refseq_simulated_metagenome.zip extrait avec succès.\n",
      "\n",
      "Téléchargement de deephage-dataset.7z depuis Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13KfvYgR946gnzBAaM3TYsGPUwvoqlN-Z\n",
      "To: d:\\K Docs\\Phagos x AWS\\phage-classification-hackathon\\deephage-dataset.7z\n",
      "100%|██████████| 29.5M/29.5M [00:00<00:00, 42.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction de deephage-dataset.7z...\n",
      "deephage-dataset.7z extrait avec succès.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import py7zr\n",
    "import gdown\n",
    "\n",
    "# ---------- FONCTIONS DE TÉLÉCHARGEMENT & EXTRACTION ----------\n",
    "\n",
    "def download_and_extract_zip(url, extract_to, archive_name):\n",
    "    print(f\"Téléchargement de {archive_name} (ZIP)...\")\n",
    "    gdown.download(url, archive_name, quiet=False)\n",
    "    print(f\"Extraction de {archive_name}...\")\n",
    "    with zipfile.ZipFile(archive_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path=extract_to)\n",
    "    os.remove(archive_name)\n",
    "    print(f\"{archive_name} extrait avec succès.\\n\")\n",
    "\n",
    "def download_and_extract_7z_from_drive(file_id, extract_to, archive_name):\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    print(f\"Téléchargement de {archive_name} depuis Google Drive...\")\n",
    "    gdown.download(id=file_id, output=archive_name, quiet=False)\n",
    "    print(f\"Extraction de {archive_name}...\")\n",
    "    with py7zr.SevenZipFile(archive_name, mode='r') as archive:\n",
    "        archive.extractall(path=extract_to)\n",
    "    os.remove(archive_name)\n",
    "    print(f\"{archive_name} extrait avec succès.\\n\")\n",
    "\n",
    "# ---------- CRÉATION DES DOSSIERS ----------\n",
    "\n",
    "os.makedirs(\"datasets/refseq_simulated_metagenome\", exist_ok=True)\n",
    "os.makedirs(\"datasets/deephage_lifestyle\", exist_ok=True)\n",
    "\n",
    "# ---------- 1. DATASET REFSEQ ----------\n",
    "\n",
    "refseq_url = \"https://figshare.com/ndownloader/articles/19739884/versions/1\"\n",
    "download_and_extract_zip(\n",
    "    refseq_url,\n",
    "    \"datasets/refseq_simulated_metagenome\",\n",
    "    \"refseq_simulated_metagenome.zip\"\n",
    ")\n",
    "\n",
    "# ---------- 2. DATASET DEEPHAGE ----------\n",
    "\n",
    "deephage_file_id = \"13KfvYgR946gnzBAaM3TYsGPUwvoqlN-Z\"\n",
    "download_and_extract_7z_from_drive(\n",
    "    deephage_file_id,\n",
    "    \"datasets/deephage_lifestyle\",\n",
    "    \"deephage-dataset.7z\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3a93c-4f9e-47e7-9c05-df9f424000a5",
   "metadata": {},
   "source": [
    "### Chargement des séquences FASTA DeePhage\n",
    "\n",
    "Nous utilisons uniquement les séquences **annotées manuellement** :\n",
    "\n",
    "- `Dataset-1_virulent.fasta` → phages **lytiques** (label `1`)\n",
    "- `Dataset-1_temperate.fasta` → phages **lysogéniques** (label `0`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e1dd36-387a-4075-8875-3209c9b4b8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 séquences chargées.\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "def load_sequences(fasta_file, label):\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append((str(record.seq), label))\n",
    "    return sequences\n",
    "\n",
    "# Charger les deux jeux\n",
    "data = []\n",
    "data += load_sequences(\"datasets/deephage_lifestyle/Dataset-1_virulent.fasta\", 1)\n",
    "data += load_sequences(\"datasets/deephage_lifestyle/Dataset-1_temperate.fasta\", 0)\n",
    "\n",
    "print(f\"{len(data)} séquences chargées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a83ed-52ba-4ade-84af-ef599d93a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    return list(sequences), list(labels)\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=64, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19fcd3e-b493-475e-ac88-70a2b0a09d0b",
   "metadata": {},
   "source": [
    "### Génération des embeddings avec Evo\n",
    "\n",
    "On encode chaque séquence d’ADN en un vecteur de représentation à l’aide du modèle `Evo`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4015bb6a-bf8c-44e2-922b-6bcdfe3c5fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31021f2358e483fadc88a79783cea2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "StripedHyena(\n",
       "  (embedding_layer): VocabParallelEmbedding(512, 4096)\n",
       "  (norm): RMSNorm()\n",
       "  (unembed): VocabParallelEmbedding(512, 4096)\n",
       "  (blocks): ModuleList(\n",
       "    (0-7): 8 x ParallelGatedConvBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (filter): ParallelHyenaFilter()\n",
       "      (projections): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "      (out_filter_dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): AttentionBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (inner_mha_cls): MHA(\n",
       "        (Wqkv): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "        (inner_attn): FlashSelfAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (inner_cross_attn): FlashCrossAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (rotary_emb): LinearlyScaledRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9-15): 7 x ParallelGatedConvBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (filter): ParallelHyenaFilter()\n",
       "      (projections): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "      (out_filter_dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (16): AttentionBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (inner_mha_cls): MHA(\n",
       "        (Wqkv): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "        (inner_attn): FlashSelfAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (inner_cross_attn): FlashCrossAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (rotary_emb): LinearlyScaledRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (17-23): 7 x ParallelGatedConvBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (filter): ParallelHyenaFilter()\n",
       "      (projections): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "      (out_filter_dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (24): AttentionBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (inner_mha_cls): MHA(\n",
       "        (Wqkv): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "        (inner_attn): FlashSelfAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (inner_cross_attn): FlashCrossAttention(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (out_proj): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (rotary_emb): LinearlyScaledRotaryEmbedding()\n",
       "      )\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "    (25-31): 7 x ParallelGatedConvBlock(\n",
       "      (pre_norm): RMSNorm()\n",
       "      (post_norm): RMSNorm()\n",
       "      (filter): ParallelHyenaFilter()\n",
       "      (projections): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "      (out_filter_dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (mlp): ParallelGatedMLP(\n",
       "        (l1): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l2): Linear(in_features=4096, out_features=10928, bias=False)\n",
       "        (l3): Linear(in_features=10928, out_features=4096, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evo import Evo\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "evo_model = Evo(\"evo-1-131k-base\")\n",
    "model, tokenizer = evo_model.model, evo_model.tokenizer\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73ec05e-fd79-44db-858f-a4cb1555b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representation(sequence):\n",
    "    tokens = tokenizer.tokenize(sequence)\n",
    "    input_ids = torch.tensor(tokens, dtype=torch.int32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(input_ids)\n",
    "    return logits.mean(dim=1).squeeze().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f077ec-ae2c-4816-8f46-c09b53fcf840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading...:  50%|█████     | 2/4 [00:00<00:00,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Erreur: CUDA out of memory. Tried to allocate 8.96 GiB. GPU 0 has a total capacity of 21.98 GiB of which 7.61 GiB is free. Including non-PyTorch memory, this process has 14.36 GiB memory in use. Of the allocated memory 14.05 GiB is allocated by PyTorch, and 9.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables), ex: agttaataatttactcgtatagctcagtgg...\n",
      "[1] Erreur: CUDA out of memory. Tried to allocate 10.67 GiB. GPU 0 has a total capacity of 21.98 GiB of which 6.73 GiB is free. Including non-PyTorch memory, this process has 15.24 GiB memory in use. Of the allocated memory 14.43 GiB is allocated by PyTorch, and 526.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables), ex: aaaagtaggtgatagtataagatgactaaa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading...:  75%|███████▌  | 3/4 [00:00<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Erreur: CUDA out of memory. Tried to allocate 3.04 GiB. GPU 0 has a total capacity of 21.98 GiB of which 2.48 GiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 19.17 GiB is allocated by PyTorch, and 10.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables), ex: gtcccgcccccataggacacgctaaccaaa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Erreur: CUDA out of memory. Tried to allocate 11.88 GiB. GPU 0 has a total capacity of 21.98 GiB of which 5.52 GiB is free. Including non-PyTorch memory, this process has 16.45 GiB memory in use. Of the allocated memory 14.69 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables), ex: gtcaaattttcacgcccgcgaaaaatgaaa...\n",
      "Aucun embedding valide généré.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "progressBar = tqdm(dataloader, desc=\"Loading...\", leave=False)\n",
    "\n",
    "for i, (seq, label) in enumerate(progressBar):\n",
    "    try:\n",
    "        # Corriger le type : si seq est une liste, prendre le premier élément\n",
    "        if isinstance(seq, (list, tuple)):\n",
    "            seq = seq[0]\n",
    "        # Vérifier que c’est bien une string\n",
    "        if not isinstance(seq, str):\n",
    "            seq = str(seq)\n",
    "\n",
    "        rep = get_representation(seq)  # doit renvoyer un np.array ou torch tensor\n",
    "        X.append(rep)\n",
    "        y.append(label)\n",
    "    except Exception as e:\n",
    "        snippet = seq[:30] if isinstance(seq, str) else str(seq)[:30]\n",
    "        print(f\"[{i}] Erreur: {e}, ex: {snippet}...\")\n",
    "\n",
    "# Ne pas empiler si vide\n",
    "if X:\n",
    "    X = np.stack(X)\n",
    "    y = np.array(y)\n",
    "    print(\"Forme finale de X:\", X.shape)\n",
    "    print(\"Forme finale de y:\", y.shape)\n",
    "else:\n",
    "    print(\"Aucun embedding valide généré.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0e2d1f-e032-4372-9fe6-89abbde3fda1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Split\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Modèle\u001b[39;00m\n\u001b[1;32m     10\u001b[0m clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m~/SageMaker/project-gamma/evo_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/SageMaker/project-gamma/evo_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/SageMaker/project-gamma/evo_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2481\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2478\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2485\u001b[0m     )\n\u001b[1;32m   2487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modèle\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Résultats\n",
    "print(\"Rapport de classification :\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Lysogenic\", \"Lytic\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340272e1-6874-4b7c-b06e-8abcd0395f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_tsne[y==0,0], X_tsne[y==0,1], c=\"blue\", label=\"Lysogenic (0)\", alpha=0.6)\n",
    "plt.scatter(X_tsne[y==1,0], X_tsne[y==1,1], c=\"red\", label=\"Lytic (1)\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.title(\"Projection t-SNE des séquences phage (Evo embeddings)\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45cf09-1e04-4c60-a4ea-ce854cd953de",
   "metadata": {},
   "source": [
    "### Classification des phages : modèle de régression logistique\n",
    "\n",
    "On entraîne un classifieur supervisé (`LogisticRegression`) pour prédire le style de vie du phage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f6bedb-e8c7-48c1-8339-89b4b0121241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4667d45-25f6-4664-af94-fd5fce1d45ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
