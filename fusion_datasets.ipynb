{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c198b5-d9c4-4f96-bc18-7822ed9ca2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n~/datasets/...\\n\\n\\nphage_fragmented/\\nx4\\n    - Dataset-1_temperate.fasta\\n\\n        => >Temp_gi|149|ref|NC_013055| Burkholderia phage KS9 linear:0-12169:1\\n            => >Temp\\n    idem pour viru\\n\\n    - Dataset-1_virulent.fasta\\n    - Dataset-2_temperate.fasta\\n    - Dataset-2_virulent.fasta\\n    \\nrefseq_simulated_metagenome/\\n    - host_chr_pvog_fragments.fasta\\n       => BACT\\n\\n\\n>Viru\\nACTG\\n\\n>Temp\\nACTG\\n\\n>Bact\\nACTG\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "~/datasets/...\n",
    "\n",
    "\n",
    "phage_fragmented/\n",
    "x4\n",
    "    - Dataset-1_temperate.fasta\n",
    "\n",
    "        => >Temp_gi|149|ref|NC_013055| Burkholderia phage KS9 linear:0-12169:1\n",
    "            => >Temp\n",
    "    idem pour viru\n",
    "\n",
    "    - Dataset-1_virulent.fasta\n",
    "    - Dataset-2_temperate.fasta\n",
    "    - Dataset-2_virulent.fasta\n",
    "    \n",
    "refseq_simulated_metagenome/\n",
    "    - host_chr_pvog_fragments.fasta\n",
    "       => BACT\n",
    "\n",
    "\n",
    ">Viru\n",
    "ACTG\n",
    "\n",
    ">Temp\n",
    "ACTG\n",
    "\n",
    ">Bact\n",
    "ACTG\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45c7190-0241-46bf-8695-47c97ff41f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les séquences ont été fusionnées et enregistrées dans datasets/fusion_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Chemins vers les dossiers contenant les fichiers .fasta\n",
    "phage_dir = 'datasets/phage_fragmented/'\n",
    "refseq_dir = 'datasets/refseq_simulated_metagenome/'\n",
    "\n",
    "# Liste des fichiers à traiter\n",
    "fichiers = [\n",
    "    'Dataset-2_temperate_fragmented.fasta',\n",
    "    'Dataset-1_virulent_fragmented.fasta',\n",
    "    'Dataset-2_virulent_fragmented.fasta',\n",
    "    'Dataset-1_temperate_fragmented.fasta',\n",
    "    'host_chr_pvog_fragments.fasta'\n",
    "]\n",
    "\n",
    "# Chemin du fichier de sortie (dans le dossier datasets)\n",
    "output_file = 'datasets/fusion_sequences.fasta'\n",
    "\n",
    "# Créer le dossier 'datasets' si nécessaire\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Fonction pour extraire et modifier l'en-tête\n",
    "def modifier_header(header):\n",
    "    # Extraire la première colonne avant le premier \"|\"\n",
    "    first_column = header.split('|')[0]\n",
    "    if first_column.startswith(\">Viru\"):\n",
    "        return \">Viru\"\n",
    "    elif first_column.startswith(\">Temp\"):\n",
    "        return \">Temp\"\n",
    "    else:\n",
    "        return \">Bact\"\n",
    "\n",
    "# Fonction pour lire et fusionner les séquences\n",
    "def fusionner_sequences():\n",
    "    with open(output_file, 'w') as output:\n",
    "        # Traitement des fichiers du dossier phage_fragmented\n",
    "        for filename in fichiers:\n",
    "            file_path = None\n",
    "            if filename in os.listdir(phage_dir):\n",
    "                file_path = os.path.join(phage_dir, filename)\n",
    "            elif filename in os.listdir(refseq_dir):\n",
    "                file_path = os.path.join(refseq_dir, filename)\n",
    "\n",
    "            if file_path:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    header = None\n",
    "                    sequence = []\n",
    "                    for line in file:\n",
    "                        line = line.strip()\n",
    "                        if line.startswith('>'):\n",
    "                            # Si on a déjà une séquence, on l'écrit dans le fichier\n",
    "                            if header:\n",
    "                                output.write(f\"{header}\\n\")\n",
    "                                output.write(''.join(sequence) + '\\n')\n",
    "                            # Nouveau header\n",
    "                            header = modifier_header(line)\n",
    "                            sequence = []\n",
    "                        else:\n",
    "                            sequence.append(line)\n",
    "                    # Ajouter la dernière séquence lue\n",
    "                    if header:\n",
    "                        output.write(f\"{header}\\n\")\n",
    "                        output.write(''.join(sequence) + '\\n')\n",
    "\n",
    "# Exécution de la fusion\n",
    "fusionner_sequences()\n",
    "print(f\"Les séquences ont été fusionnées et enregistrées dans {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59cf0bb2-641e-4494-b162-194bbb1cc853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viru : 11565\n",
      "Temp : 2769\n",
      "Bact : 104003\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour compter les occurrences de Bact, Temp, et Viru dans le fichier\n",
    "def compter_occurrences(fichier):\n",
    "    counts = {'Bact': 0, 'Temp': 0, 'Viru': 0}\n",
    "    \n",
    "    with open(fichier, 'r') as file:\n",
    "        for line in file:\n",
    "            # Vérifier si la ligne est un en-tête\n",
    "            if line.startswith('>'):\n",
    "                # Vérifier le début de l'en-tête\n",
    "                if line.startswith('>Viru'):\n",
    "                    counts['Viru'] += 1\n",
    "                elif line.startswith('>Temp'):\n",
    "                    counts['Temp'] += 1\n",
    "                else:\n",
    "                    counts['Bact'] += 1\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Appeler la fonction pour compter les occurrences dans le fichier fusionné\n",
    "resultats = compter_occurrences('datasets/fusion_sequences.fasta')\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Viru : {resultats['Viru']}\")\n",
    "print(f\"Temp : {resultats['Temp']}\")\n",
    "print(f\"Bact : {resultats['Bact']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5827a1d7-46a4-43eb-b1eb-2170bd565d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Fonction pour afficher les 50 premières lignes du fichier fusionné (en-tête + séquences)\\ndef afficher_head(fichier, n_lignes=50):\\n    with open(fichier, 'r') as file:\\n        count = 0\\n        for line in file:\\n            if count < n_lignes:\\n                print(line.strip())  # Affiche chaque ligne sans sauter de ligne supplémentaire\\n                count += 1\\n            else:\\n                break\\n\\n# Appeler la fonction pour afficher les 50 premières lignes du fichier fusionné\\nafficher_head('datasets/fusion_sequences_shuffled.fasta', n_lignes=50)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Fonction pour afficher les 50 premières lignes du fichier fusionné (en-tête + séquences)\n",
    "def afficher_head(fichier, n_lignes=50):\n",
    "    with open(fichier, 'r') as file:\n",
    "        count = 0\n",
    "        for line in file:\n",
    "            if count < n_lignes:\n",
    "                print(line.strip())  # Affiche chaque ligne sans sauter de ligne supplémentaire\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# Appeler la fonction pour afficher les 50 premières lignes du fichier fusionné\n",
    "afficher_head('datasets/fusion_sequences_shuffled.fasta', n_lignes=50)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d41f2836-5c6c-42b0-9611-b467401d1179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from Bio import SeqIO\\nimport random\\n\\ninput_fasta = \"datasets/fusion_sequences.fasta\"\\nshuffled_fasta = \"datasets/fusion_sequences_shuffled.fasta\"\\n\\n# Lire toutes les séquences\\nrecords = list(SeqIO.parse(input_fasta, \"fasta\"))\\n\\n# Mélanger aléatoirement\\nrandom.shuffle(records)\\n\\n# Écrire dans un nouveau fichier\\nwith open(shuffled_fasta, \"w\") as out_f:\\n    SeqIO.write(records, out_f, \"fasta\")\\n\\nprint(f\"{len(records)} séquences mélangées écrites dans : {shuffled_fasta}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from Bio import SeqIO\n",
    "import random\n",
    "\n",
    "input_fasta = \"datasets/fusion_sequences.fasta\"\n",
    "shuffled_fasta = \"datasets/fusion_sequences_shuffled.fasta\"\n",
    "\n",
    "# Lire toutes les séquences\n",
    "records = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "\n",
    "# Mélanger aléatoirement\n",
    "random.shuffle(records)\n",
    "\n",
    "# Écrire dans un nouveau fichier\n",
    "with open(shuffled_fasta, \"w\") as out_f:\n",
    "    SeqIO.write(records, out_f, \"fasta\")\n",
    "\n",
    "print(f\"{len(records)} séquences mélangées écrites dans : {shuffled_fasta}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd36d0e-59ff-48c6-b467-e6b0b81dc999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from Bio import SeqIO\\nfrom Bio.SeqRecord import SeqRecord\\n\\n# Fichier d\\'entrée/sortie (même nom, on écrase)\\nfasta_path = \"datasets/fusion_sequences_shuffled.fasta\"\\n\\n# Lire, modifier les IDs, puis réécrire\\nrecords = []\\nfor i, record in enumerate(SeqIO.parse(fasta_path, \"fasta\")):\\n    new_id = f\"{record.id}_{i:05d}\"  # Exemple : Bact_00000, Temp_00001, etc.\\n    new_record = SeqRecord(record.seq, id=new_id, description=\"\")\\n    records.append(new_record)\\n\\nwith open(fasta_path, \"w\") as f:\\n    SeqIO.write(records, f, \"fasta\")\\n\\nprint(f\"{len(records)} séquences réécrites avec identifiants uniques dans : {fasta_path}\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Fichier d'entrée/sortie (même nom, on écrase)\n",
    "fasta_path = \"datasets/fusion_sequences_shuffled.fasta\"\n",
    "\n",
    "# Lire, modifier les IDs, puis réécrire\n",
    "records = []\n",
    "for i, record in enumerate(SeqIO.parse(fasta_path, \"fasta\")):\n",
    "    new_id = f\"{record.id}_{i:05d}\"  # Exemple : Bact_00000, Temp_00001, etc.\n",
    "    new_record = SeqRecord(record.seq, id=new_id, description=\"\")\n",
    "    records.append(new_record)\n",
    "\n",
    "with open(fasta_path, \"w\") as f:\n",
    "    SeqIO.write(records, f, \"fasta\")\n",
    "\n",
    "print(f\"{len(records)} séquences réécrites avec identifiants uniques dans : {fasta_path}\")\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d75a764-6739-4175-80c2-ffe54a0f649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de séquences dans le fichier : 118337\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "fasta_path = \"datasets/fusion_sequences_shuffled.fasta\"\n",
    "\n",
    "nb_sequences = sum(1 for _ in SeqIO.parse(fasta_path, \"fasta\"))\n",
    "print(f\"Nombre total de séquences dans le fichier : {nb_sequences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0706c4-b56f-44c9-bc31-26fd8df4567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bact_00000', 'Bact_00001', 'Bact_00002', 'Bact_00003', 'Bact_00004', 'Bact_00005', 'Bact_00006', 'Bact_00007', 'Viru_00008', 'Bact_00009']\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "ids = [rec.id for rec in SeqIO.parse(\"datasets/fusion_sequences_shuffled.fasta\", \"fasta\")][:10]\n",
    "print(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80c9e3d-6cc7-4ed8-b609-148b31879733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066affb4d4994e809a22a42098e6e350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed31d1feca9d403d94601c7d6a5dda30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_hyena.py:   0%|          | 0.00/3.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- configuration_hyena.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b69796043e4a1d90eeb317ae3f2da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_hyena.py:   0%|          | 0.00/5.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad08dd3fb5140eab482b245bed174d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "engine.py:   0%|          | 0.00/13.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a179cd415e4d2eb85a100e7e631c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "utils.py:   0%|          | 0.00/2.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- engine.py\n",
      "- utils.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11871fb68b2948d9a7ff764a1d0810da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cache.py:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- cache.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f52019fed8433d9432e08cd6663fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "layers.py:   0%|          | 0.00/5.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- layers.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30e84259e374bf18acb0af4cc1581de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.py:   0%|          | 0.00/19.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90adb36accd2423894f9600e2d54e43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "positional_embeddings.py:   0%|          | 0.00/4.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- positional_embeddings.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb764b555fc4b8aab6cfd770996e31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.py:   0%|          | 0.00/4.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- model.py\n",
      "- positional_embeddings.py\n",
      "- tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/togethercomputer/evo-1-131k-base:\n",
      "- modeling_hyena.py\n",
      "- engine.py\n",
      "- cache.py\n",
      "- layers.py\n",
      "- model.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0afac7f5cc4c26aab9dd42b0372f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/34.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3afb6c724aa4b21af10cdd8a65931e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be791e10f58d4489b3db0c139b2e36ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39348e8fad90405a92fb98218141050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba38ebcf1b2e4e228c19cdec2c31e893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/3.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1539f431372492495a9aa4a340ac1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f452b0e1ac143dc817f21ed63d2a642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 37it [00:41,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 embeddings finaux générés.\n",
      "Séquences traitées : ['Bact_00000', 'Bact_00001', 'Bact_00002', 'Bact_00003', 'Bact_00004', 'Bact_00005', 'Bact_00006', 'Bact_00007', 'Viru_00008', 'Bact_00009']\n",
      "Dimension d’un embedding : torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO \n",
    "import torch\n",
    "from evo import Evo\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Paramètres\n",
    "fasta_in = \"datasets/fusion_sequences_shuffled.fasta\"  # fichier shuffle\n",
    "batch_size = 8\n",
    "window = 256\n",
    "max_seqs = 10  # Limite à 10 séquences\n",
    "\n",
    "# Charger le modèle Evo-1-8k-base sur GPU\n",
    "evo_model = Evo('evo-1-8k-base')\n",
    "model, tokenizer = evo_model.model, evo_model.tokenizer\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "\n",
    "# Générateur de fenêtres (on saute les vides)\n",
    "def windows(seq, size=window):\n",
    "    for i in range(0, len(seq), size):\n",
    "        w = seq[i:i+size]\n",
    "        if w:            # ignore les chaînes vides\n",
    "            yield w\n",
    "\n",
    "# Générateur limité aux N premières séquences\n",
    "def process_first_n_fasta(fasta, batch_size, max_seqs):\n",
    "    buffer_w, buffer_id = [], []\n",
    "    count = 0\n",
    "    for rec in SeqIO.parse(fasta, \"fasta\"):\n",
    "        if count >= max_seqs:\n",
    "            break\n",
    "        for w in windows(str(rec.seq)):\n",
    "            buffer_w.append(w)\n",
    "            buffer_id.append(rec.id)\n",
    "            if len(buffer_w) == batch_size:\n",
    "                yield buffer_w, buffer_id\n",
    "                buffer_w, buffer_id = [], []\n",
    "        count += 1\n",
    "    if buffer_w:\n",
    "        yield buffer_w, buffer_id\n",
    "\n",
    "# Traitement\n",
    "all_embs = {}  # { seq_id: [window_emb1, window_emb2, ...] }\n",
    "\n",
    "for windows_batch, ids_batch in tqdm(\n",
    "        process_first_n_fasta(fasta_in, batch_size, max_seqs),\n",
    "        desc=\"Batches\"):\n",
    "    # 1) Tokenisation\n",
    "    tensors = [torch.tensor(tokenizer.tokenize(w)) for w in windows_batch]\n",
    "    padded = pad_sequence(\n",
    "        tensors, batch_first=True, padding_value=tokenizer.pad_id\n",
    "    ).to(device).long()\n",
    "\n",
    "    # 2) Padding mask\n",
    "    padding_mask = (padded != tokenizer.pad_id).to(device)\n",
    "\n",
    "    # 3) Inférence\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        outputs = model(padded, padding_mask=padding_mask)[0]  # (batch, L, D)\n",
    "\n",
    "    # 4) Pooling sur la longueur, ignore pad\n",
    "    mask = padding_mask.unsqueeze(-1)         # (batch, L, 1)\n",
    "    summed = (outputs * mask).sum(dim=1)      # (batch, D)\n",
    "    lengths = mask.sum(dim=1)                 # (batch, 1)\n",
    "    lengths[lengths == 0] = 1                 # empêche division par zéro\n",
    "    embs = (summed / lengths).cpu()           # (batch, D)\n",
    "\n",
    "    # 5) Regroupement par séquence\n",
    "    for seq_id, emb in zip(ids_batch, embs):\n",
    "        all_embs.setdefault(seq_id, []).append(emb)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# 6) Moyenne finale : 1 embedding par séquence\n",
    "final_embeddings = {\n",
    "    seq_id: torch.stack(embs, 0).mean(dim=0)\n",
    "    for seq_id, embs in all_embs.items()\n",
    "}\n",
    "\n",
    "# Affichage\n",
    "print(f\"{len(final_embeddings)} embeddings finaux générés.\")\n",
    "print(\"Séquences traitées :\", list(final_embeddings.keys())[:10])\n",
    "print(\"Dimension d’un embedding :\", next(iter(final_embeddings.values())).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b0c27f9-2d78-445a-8a2e-498d1ae06aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bact_00000 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00001 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00002 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00003 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00004 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00005 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00006 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00007 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Viru_00008 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n",
      "Bact_00009 → [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]...\n"
     ]
    }
   ],
   "source": [
    "for seq_id, emb in final_embeddings.items():\n",
    "    print(f\"{seq_id} → {emb.tolist()[:10]}...\")  # Affiche les 10 premières valeurs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (evo_env)",
   "language": "python",
   "name": "evo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
